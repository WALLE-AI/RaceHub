{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9977670264235208,
  "eval_steps": 500,
  "global_step": 1342,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0148864905098623,
      "grad_norm": 3.044605255126953,
      "learning_rate": 9.92548435171386e-05,
      "loss": 0.5832,
      "step": 10
    },
    {
      "epoch": 0.0297729810197246,
      "grad_norm": 3.3845067024230957,
      "learning_rate": 9.85096870342772e-05,
      "loss": 0.345,
      "step": 20
    },
    {
      "epoch": 0.0446594715295869,
      "grad_norm": 3.0028531551361084,
      "learning_rate": 9.77645305514158e-05,
      "loss": 0.3024,
      "step": 30
    },
    {
      "epoch": 0.0595459620394492,
      "grad_norm": 2.2162485122680664,
      "learning_rate": 9.70193740685544e-05,
      "loss": 0.2462,
      "step": 40
    },
    {
      "epoch": 0.0744324525493115,
      "grad_norm": 1.9673997163772583,
      "learning_rate": 9.6274217585693e-05,
      "loss": 0.2445,
      "step": 50
    },
    {
      "epoch": 0.0893189430591738,
      "grad_norm": 2.4761085510253906,
      "learning_rate": 9.55290611028316e-05,
      "loss": 0.2289,
      "step": 60
    },
    {
      "epoch": 0.1042054335690361,
      "grad_norm": 2.2324206829071045,
      "learning_rate": 9.47839046199702e-05,
      "loss": 0.2358,
      "step": 70
    },
    {
      "epoch": 0.1190919240788984,
      "grad_norm": 2.6178953647613525,
      "learning_rate": 9.40387481371088e-05,
      "loss": 0.2221,
      "step": 80
    },
    {
      "epoch": 0.1339784145887607,
      "grad_norm": 2.76466703414917,
      "learning_rate": 9.32935916542474e-05,
      "loss": 0.2204,
      "step": 90
    },
    {
      "epoch": 0.148864905098623,
      "grad_norm": 2.281511068344116,
      "learning_rate": 9.2548435171386e-05,
      "loss": 0.1979,
      "step": 100
    },
    {
      "epoch": 0.1637513956084853,
      "grad_norm": 1.8820831775665283,
      "learning_rate": 9.18032786885246e-05,
      "loss": 0.1968,
      "step": 110
    },
    {
      "epoch": 0.1786378861183476,
      "grad_norm": 1.6494356393814087,
      "learning_rate": 9.10581222056632e-05,
      "loss": 0.1693,
      "step": 120
    },
    {
      "epoch": 0.1935243766282099,
      "grad_norm": 2.2706539630889893,
      "learning_rate": 9.031296572280179e-05,
      "loss": 0.1687,
      "step": 130
    },
    {
      "epoch": 0.2084108671380722,
      "grad_norm": 1.9134743213653564,
      "learning_rate": 8.956780923994039e-05,
      "loss": 0.1674,
      "step": 140
    },
    {
      "epoch": 0.22329735764793449,
      "grad_norm": 1.7877248525619507,
      "learning_rate": 8.882265275707899e-05,
      "loss": 0.1886,
      "step": 150
    },
    {
      "epoch": 0.2381838481577968,
      "grad_norm": 2.2359635829925537,
      "learning_rate": 8.807749627421758e-05,
      "loss": 0.1521,
      "step": 160
    },
    {
      "epoch": 0.2530703386676591,
      "grad_norm": 1.4516674280166626,
      "learning_rate": 8.733233979135618e-05,
      "loss": 0.18,
      "step": 170
    },
    {
      "epoch": 0.2679568291775214,
      "grad_norm": 2.0498220920562744,
      "learning_rate": 8.65871833084948e-05,
      "loss": 0.1887,
      "step": 180
    },
    {
      "epoch": 0.2828433196873837,
      "grad_norm": 1.6504793167114258,
      "learning_rate": 8.58420268256334e-05,
      "loss": 0.1498,
      "step": 190
    },
    {
      "epoch": 0.297729810197246,
      "grad_norm": 1.984366536140442,
      "learning_rate": 8.509687034277199e-05,
      "loss": 0.1928,
      "step": 200
    },
    {
      "epoch": 0.3126163007071083,
      "grad_norm": 2.330489158630371,
      "learning_rate": 8.435171385991059e-05,
      "loss": 0.159,
      "step": 210
    },
    {
      "epoch": 0.3275027912169706,
      "grad_norm": 1.5565944910049438,
      "learning_rate": 8.360655737704919e-05,
      "loss": 0.1697,
      "step": 220
    },
    {
      "epoch": 0.3423892817268329,
      "grad_norm": 1.5508005619049072,
      "learning_rate": 8.286140089418778e-05,
      "loss": 0.1627,
      "step": 230
    },
    {
      "epoch": 0.3572757722366952,
      "grad_norm": 2.05908465385437,
      "learning_rate": 8.211624441132638e-05,
      "loss": 0.1291,
      "step": 240
    },
    {
      "epoch": 0.3721622627465575,
      "grad_norm": 3.0104126930236816,
      "learning_rate": 8.137108792846498e-05,
      "loss": 0.1662,
      "step": 250
    },
    {
      "epoch": 0.3870487532564198,
      "grad_norm": 1.4011229276657104,
      "learning_rate": 8.062593144560357e-05,
      "loss": 0.1344,
      "step": 260
    },
    {
      "epoch": 0.4019352437662821,
      "grad_norm": 1.8277969360351562,
      "learning_rate": 7.988077496274217e-05,
      "loss": 0.157,
      "step": 270
    },
    {
      "epoch": 0.4168217342761444,
      "grad_norm": 1.8608802556991577,
      "learning_rate": 7.913561847988077e-05,
      "loss": 0.144,
      "step": 280
    },
    {
      "epoch": 0.4317082247860067,
      "grad_norm": 1.487466812133789,
      "learning_rate": 7.839046199701938e-05,
      "loss": 0.1529,
      "step": 290
    },
    {
      "epoch": 0.44659471529586897,
      "grad_norm": 1.9486188888549805,
      "learning_rate": 7.764530551415798e-05,
      "loss": 0.1506,
      "step": 300
    },
    {
      "epoch": 0.4614812058057313,
      "grad_norm": 2.5252768993377686,
      "learning_rate": 7.690014903129658e-05,
      "loss": 0.1483,
      "step": 310
    },
    {
      "epoch": 0.4763676963155936,
      "grad_norm": 1.4017573595046997,
      "learning_rate": 7.615499254843518e-05,
      "loss": 0.1435,
      "step": 320
    },
    {
      "epoch": 0.4912541868254559,
      "grad_norm": 1.6509580612182617,
      "learning_rate": 7.540983606557377e-05,
      "loss": 0.1055,
      "step": 330
    },
    {
      "epoch": 0.5061406773353182,
      "grad_norm": 2.3008170127868652,
      "learning_rate": 7.466467958271237e-05,
      "loss": 0.1402,
      "step": 340
    },
    {
      "epoch": 0.5210271678451805,
      "grad_norm": 2.147451639175415,
      "learning_rate": 7.391952309985097e-05,
      "loss": 0.1282,
      "step": 350
    },
    {
      "epoch": 0.5359136583550428,
      "grad_norm": 1.372272253036499,
      "learning_rate": 7.317436661698958e-05,
      "loss": 0.1479,
      "step": 360
    },
    {
      "epoch": 0.5508001488649051,
      "grad_norm": 2.9437766075134277,
      "learning_rate": 7.242921013412816e-05,
      "loss": 0.1316,
      "step": 370
    },
    {
      "epoch": 0.5656866393747674,
      "grad_norm": 2.1059746742248535,
      "learning_rate": 7.168405365126677e-05,
      "loss": 0.1415,
      "step": 380
    },
    {
      "epoch": 0.5805731298846297,
      "grad_norm": 1.6477367877960205,
      "learning_rate": 7.093889716840537e-05,
      "loss": 0.116,
      "step": 390
    },
    {
      "epoch": 0.595459620394492,
      "grad_norm": 2.0597355365753174,
      "learning_rate": 7.019374068554397e-05,
      "loss": 0.1313,
      "step": 400
    },
    {
      "epoch": 0.6103461109043543,
      "grad_norm": 1.3768768310546875,
      "learning_rate": 6.944858420268257e-05,
      "loss": 0.126,
      "step": 410
    },
    {
      "epoch": 0.6252326014142165,
      "grad_norm": 1.62981379032135,
      "learning_rate": 6.870342771982117e-05,
      "loss": 0.1422,
      "step": 420
    },
    {
      "epoch": 0.6401190919240789,
      "grad_norm": 1.7939075231552124,
      "learning_rate": 6.795827123695977e-05,
      "loss": 0.1603,
      "step": 430
    },
    {
      "epoch": 0.6550055824339412,
      "grad_norm": 1.4026342630386353,
      "learning_rate": 6.721311475409836e-05,
      "loss": 0.1345,
      "step": 440
    },
    {
      "epoch": 0.6698920729438035,
      "grad_norm": 1.6670386791229248,
      "learning_rate": 6.646795827123696e-05,
      "loss": 0.1085,
      "step": 450
    },
    {
      "epoch": 0.6847785634536658,
      "grad_norm": 1.8869165182113647,
      "learning_rate": 6.572280178837557e-05,
      "loss": 0.118,
      "step": 460
    },
    {
      "epoch": 0.6996650539635281,
      "grad_norm": 1.9979963302612305,
      "learning_rate": 6.497764530551415e-05,
      "loss": 0.1108,
      "step": 470
    },
    {
      "epoch": 0.7145515444733904,
      "grad_norm": 1.783379316329956,
      "learning_rate": 6.423248882265276e-05,
      "loss": 0.1379,
      "step": 480
    },
    {
      "epoch": 0.7294380349832527,
      "grad_norm": 1.3614184856414795,
      "learning_rate": 6.348733233979136e-05,
      "loss": 0.1468,
      "step": 490
    },
    {
      "epoch": 0.744324525493115,
      "grad_norm": 1.7545247077941895,
      "learning_rate": 6.274217585692996e-05,
      "loss": 0.1333,
      "step": 500
    },
    {
      "epoch": 0.7592110160029772,
      "grad_norm": 2.3432939052581787,
      "learning_rate": 6.199701937406855e-05,
      "loss": 0.1177,
      "step": 510
    },
    {
      "epoch": 0.7740975065128396,
      "grad_norm": 1.1559795141220093,
      "learning_rate": 6.125186289120715e-05,
      "loss": 0.1116,
      "step": 520
    },
    {
      "epoch": 0.7889839970227019,
      "grad_norm": 1.2145674228668213,
      "learning_rate": 6.050670640834576e-05,
      "loss": 0.1398,
      "step": 530
    },
    {
      "epoch": 0.8038704875325642,
      "grad_norm": 1.693647861480713,
      "learning_rate": 5.976154992548435e-05,
      "loss": 0.1157,
      "step": 540
    },
    {
      "epoch": 0.8187569780424265,
      "grad_norm": 1.695283055305481,
      "learning_rate": 5.9016393442622956e-05,
      "loss": 0.1363,
      "step": 550
    },
    {
      "epoch": 0.8336434685522888,
      "grad_norm": 1.8138513565063477,
      "learning_rate": 5.827123695976156e-05,
      "loss": 0.144,
      "step": 560
    },
    {
      "epoch": 0.8485299590621511,
      "grad_norm": 1.2213635444641113,
      "learning_rate": 5.752608047690016e-05,
      "loss": 0.1009,
      "step": 570
    },
    {
      "epoch": 0.8634164495720134,
      "grad_norm": 1.3465749025344849,
      "learning_rate": 5.678092399403875e-05,
      "loss": 0.1327,
      "step": 580
    },
    {
      "epoch": 0.8783029400818757,
      "grad_norm": 1.5790951251983643,
      "learning_rate": 5.603576751117735e-05,
      "loss": 0.1306,
      "step": 590
    },
    {
      "epoch": 0.8931894305917379,
      "grad_norm": 1.5735019445419312,
      "learning_rate": 5.529061102831595e-05,
      "loss": 0.1341,
      "step": 600
    },
    {
      "epoch": 0.9080759211016003,
      "grad_norm": 1.7593492269515991,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 0.1382,
      "step": 610
    },
    {
      "epoch": 0.9229624116114626,
      "grad_norm": 1.8385745286941528,
      "learning_rate": 5.380029806259315e-05,
      "loss": 0.1348,
      "step": 620
    },
    {
      "epoch": 0.9378489021213249,
      "grad_norm": 1.431243658065796,
      "learning_rate": 5.305514157973175e-05,
      "loss": 0.1193,
      "step": 630
    },
    {
      "epoch": 0.9527353926311872,
      "grad_norm": 1.905563235282898,
      "learning_rate": 5.230998509687034e-05,
      "loss": 0.1266,
      "step": 640
    },
    {
      "epoch": 0.9676218831410495,
      "grad_norm": 1.5975068807601929,
      "learning_rate": 5.156482861400894e-05,
      "loss": 0.1014,
      "step": 650
    },
    {
      "epoch": 0.9825083736509118,
      "grad_norm": 1.1472606658935547,
      "learning_rate": 5.081967213114754e-05,
      "loss": 0.1114,
      "step": 660
    },
    {
      "epoch": 0.997394864160774,
      "grad_norm": 1.2849053144454956,
      "learning_rate": 5.0074515648286144e-05,
      "loss": 0.1106,
      "step": 670
    },
    {
      "epoch": 1.0122813546706364,
      "grad_norm": 1.1391209363937378,
      "learning_rate": 4.9329359165424745e-05,
      "loss": 0.0929,
      "step": 680
    },
    {
      "epoch": 1.0271678451804986,
      "grad_norm": 1.2261319160461426,
      "learning_rate": 4.858420268256334e-05,
      "loss": 0.0801,
      "step": 690
    },
    {
      "epoch": 1.042054335690361,
      "grad_norm": 1.5937045812606812,
      "learning_rate": 4.783904619970194e-05,
      "loss": 0.096,
      "step": 700
    },
    {
      "epoch": 1.0569408262002233,
      "grad_norm": 1.0269979238510132,
      "learning_rate": 4.709388971684054e-05,
      "loss": 0.0886,
      "step": 710
    },
    {
      "epoch": 1.0718273167100856,
      "grad_norm": 1.2455142736434937,
      "learning_rate": 4.634873323397914e-05,
      "loss": 0.0795,
      "step": 720
    },
    {
      "epoch": 1.0867138072199478,
      "grad_norm": 2.1080703735351562,
      "learning_rate": 4.560357675111774e-05,
      "loss": 0.1031,
      "step": 730
    },
    {
      "epoch": 1.1016002977298103,
      "grad_norm": 1.3068312406539917,
      "learning_rate": 4.4858420268256336e-05,
      "loss": 0.107,
      "step": 740
    },
    {
      "epoch": 1.1164867882396725,
      "grad_norm": 0.9901518225669861,
      "learning_rate": 4.411326378539494e-05,
      "loss": 0.0812,
      "step": 750
    },
    {
      "epoch": 1.1313732787495347,
      "grad_norm": 1.4001165628433228,
      "learning_rate": 4.336810730253353e-05,
      "loss": 0.0871,
      "step": 760
    },
    {
      "epoch": 1.1462597692593972,
      "grad_norm": 1.018209457397461,
      "learning_rate": 4.262295081967213e-05,
      "loss": 0.0838,
      "step": 770
    },
    {
      "epoch": 1.1611462597692594,
      "grad_norm": 1.467926025390625,
      "learning_rate": 4.187779433681073e-05,
      "loss": 0.0884,
      "step": 780
    },
    {
      "epoch": 1.1760327502791217,
      "grad_norm": 1.1861363649368286,
      "learning_rate": 4.113263785394933e-05,
      "loss": 0.0662,
      "step": 790
    },
    {
      "epoch": 1.190919240788984,
      "grad_norm": 1.809603214263916,
      "learning_rate": 4.038748137108793e-05,
      "loss": 0.0864,
      "step": 800
    },
    {
      "epoch": 1.2058057312988464,
      "grad_norm": 1.6646654605865479,
      "learning_rate": 3.964232488822653e-05,
      "loss": 0.0883,
      "step": 810
    },
    {
      "epoch": 1.2206922218087086,
      "grad_norm": 1.046736478805542,
      "learning_rate": 3.889716840536513e-05,
      "loss": 0.0848,
      "step": 820
    },
    {
      "epoch": 1.2355787123185709,
      "grad_norm": 1.8021479845046997,
      "learning_rate": 3.8152011922503725e-05,
      "loss": 0.0776,
      "step": 830
    },
    {
      "epoch": 1.2504652028284333,
      "grad_norm": 1.5749006271362305,
      "learning_rate": 3.740685543964233e-05,
      "loss": 0.0871,
      "step": 840
    },
    {
      "epoch": 1.2653516933382956,
      "grad_norm": 1.3775169849395752,
      "learning_rate": 3.666169895678093e-05,
      "loss": 0.1047,
      "step": 850
    },
    {
      "epoch": 1.2802381838481578,
      "grad_norm": 1.0359094142913818,
      "learning_rate": 3.5916542473919524e-05,
      "loss": 0.0723,
      "step": 860
    },
    {
      "epoch": 1.29512467435802,
      "grad_norm": 1.7433488368988037,
      "learning_rate": 3.5171385991058126e-05,
      "loss": 0.0707,
      "step": 870
    },
    {
      "epoch": 1.3100111648678823,
      "grad_norm": 2.2255139350891113,
      "learning_rate": 3.442622950819672e-05,
      "loss": 0.083,
      "step": 880
    },
    {
      "epoch": 1.3248976553777447,
      "grad_norm": 1.3434945344924927,
      "learning_rate": 3.368107302533532e-05,
      "loss": 0.0825,
      "step": 890
    },
    {
      "epoch": 1.339784145887607,
      "grad_norm": 1.6516896486282349,
      "learning_rate": 3.2935916542473924e-05,
      "loss": 0.0899,
      "step": 900
    },
    {
      "epoch": 1.3546706363974694,
      "grad_norm": 1.5932960510253906,
      "learning_rate": 3.219076005961252e-05,
      "loss": 0.0864,
      "step": 910
    },
    {
      "epoch": 1.3695571269073317,
      "grad_norm": 1.2076479196548462,
      "learning_rate": 3.144560357675112e-05,
      "loss": 0.0778,
      "step": 920
    },
    {
      "epoch": 1.384443617417194,
      "grad_norm": 1.4972522258758545,
      "learning_rate": 3.0700447093889716e-05,
      "loss": 0.1016,
      "step": 930
    },
    {
      "epoch": 1.3993301079270561,
      "grad_norm": 1.2079274654388428,
      "learning_rate": 2.9955290611028318e-05,
      "loss": 0.0708,
      "step": 940
    },
    {
      "epoch": 1.4142165984369184,
      "grad_norm": 2.0555849075317383,
      "learning_rate": 2.9210134128166917e-05,
      "loss": 0.1008,
      "step": 950
    },
    {
      "epoch": 1.4291030889467808,
      "grad_norm": 1.7335578203201294,
      "learning_rate": 2.846497764530551e-05,
      "loss": 0.0899,
      "step": 960
    },
    {
      "epoch": 1.443989579456643,
      "grad_norm": 2.0232603549957275,
      "learning_rate": 2.7719821162444117e-05,
      "loss": 0.1022,
      "step": 970
    },
    {
      "epoch": 1.4588760699665053,
      "grad_norm": 1.4196584224700928,
      "learning_rate": 2.6974664679582712e-05,
      "loss": 0.0834,
      "step": 980
    },
    {
      "epoch": 1.4737625604763678,
      "grad_norm": 0.8909823298454285,
      "learning_rate": 2.6229508196721314e-05,
      "loss": 0.0854,
      "step": 990
    },
    {
      "epoch": 1.48864905098623,
      "grad_norm": 1.0038381814956665,
      "learning_rate": 2.5484351713859912e-05,
      "loss": 0.0878,
      "step": 1000
    },
    {
      "epoch": 1.5035355414960923,
      "grad_norm": 1.1684601306915283,
      "learning_rate": 2.473919523099851e-05,
      "loss": 0.0845,
      "step": 1010
    },
    {
      "epoch": 1.5184220320059545,
      "grad_norm": 1.582643985748291,
      "learning_rate": 2.399403874813711e-05,
      "loss": 0.096,
      "step": 1020
    },
    {
      "epoch": 1.5333085225158167,
      "grad_norm": 0.9942167401313782,
      "learning_rate": 2.324888226527571e-05,
      "loss": 0.0695,
      "step": 1030
    },
    {
      "epoch": 1.5481950130256792,
      "grad_norm": 1.49844491481781,
      "learning_rate": 2.250372578241431e-05,
      "loss": 0.0699,
      "step": 1040
    },
    {
      "epoch": 1.5630815035355416,
      "grad_norm": 2.3753154277801514,
      "learning_rate": 2.1758569299552908e-05,
      "loss": 0.086,
      "step": 1050
    },
    {
      "epoch": 1.5779679940454039,
      "grad_norm": 0.7810460329055786,
      "learning_rate": 2.1013412816691506e-05,
      "loss": 0.0659,
      "step": 1060
    },
    {
      "epoch": 1.5928544845552661,
      "grad_norm": 1.2656067609786987,
      "learning_rate": 2.0268256333830104e-05,
      "loss": 0.1041,
      "step": 1070
    },
    {
      "epoch": 1.6077409750651284,
      "grad_norm": 1.431040644645691,
      "learning_rate": 1.9523099850968703e-05,
      "loss": 0.0865,
      "step": 1080
    },
    {
      "epoch": 1.6226274655749906,
      "grad_norm": 1.059862494468689,
      "learning_rate": 1.8777943368107305e-05,
      "loss": 0.0693,
      "step": 1090
    },
    {
      "epoch": 1.6375139560848528,
      "grad_norm": 2.0177533626556396,
      "learning_rate": 1.8032786885245903e-05,
      "loss": 0.08,
      "step": 1100
    },
    {
      "epoch": 1.6524004465947153,
      "grad_norm": 1.3524922132492065,
      "learning_rate": 1.72876304023845e-05,
      "loss": 0.0692,
      "step": 1110
    },
    {
      "epoch": 1.6672869371045778,
      "grad_norm": 1.0197376012802124,
      "learning_rate": 1.65424739195231e-05,
      "loss": 0.0848,
      "step": 1120
    },
    {
      "epoch": 1.68217342761444,
      "grad_norm": 1.4799542427062988,
      "learning_rate": 1.57973174366617e-05,
      "loss": 0.0791,
      "step": 1130
    },
    {
      "epoch": 1.6970599181243022,
      "grad_norm": 0.9822513461112976,
      "learning_rate": 1.5052160953800299e-05,
      "loss": 0.0762,
      "step": 1140
    },
    {
      "epoch": 1.7119464086341645,
      "grad_norm": 1.2357659339904785,
      "learning_rate": 1.4307004470938899e-05,
      "loss": 0.0756,
      "step": 1150
    },
    {
      "epoch": 1.7268328991440267,
      "grad_norm": 1.0570082664489746,
      "learning_rate": 1.3561847988077497e-05,
      "loss": 0.069,
      "step": 1160
    },
    {
      "epoch": 1.741719389653889,
      "grad_norm": 1.0986875295639038,
      "learning_rate": 1.2816691505216097e-05,
      "loss": 0.0833,
      "step": 1170
    },
    {
      "epoch": 1.7566058801637514,
      "grad_norm": 1.348200798034668,
      "learning_rate": 1.2071535022354696e-05,
      "loss": 0.0686,
      "step": 1180
    },
    {
      "epoch": 1.7714923706736136,
      "grad_norm": 1.3167692422866821,
      "learning_rate": 1.1326378539493294e-05,
      "loss": 0.0834,
      "step": 1190
    },
    {
      "epoch": 1.786378861183476,
      "grad_norm": 1.730371117591858,
      "learning_rate": 1.0581222056631892e-05,
      "loss": 0.0974,
      "step": 1200
    },
    {
      "epoch": 1.8012653516933383,
      "grad_norm": 1.0092823505401611,
      "learning_rate": 9.836065573770493e-06,
      "loss": 0.0708,
      "step": 1210
    },
    {
      "epoch": 1.8161518422032006,
      "grad_norm": 1.5035820007324219,
      "learning_rate": 9.090909090909091e-06,
      "loss": 0.0728,
      "step": 1220
    },
    {
      "epoch": 1.8310383327130628,
      "grad_norm": 1.2651110887527466,
      "learning_rate": 8.345752608047691e-06,
      "loss": 0.0719,
      "step": 1230
    },
    {
      "epoch": 1.845924823222925,
      "grad_norm": 1.4963849782943726,
      "learning_rate": 7.60059612518629e-06,
      "loss": 0.0751,
      "step": 1240
    },
    {
      "epoch": 1.8608113137327875,
      "grad_norm": 1.1105210781097412,
      "learning_rate": 6.855439642324889e-06,
      "loss": 0.0825,
      "step": 1250
    },
    {
      "epoch": 1.8756978042426498,
      "grad_norm": 2.076080322265625,
      "learning_rate": 6.110283159463487e-06,
      "loss": 0.0774,
      "step": 1260
    },
    {
      "epoch": 1.8905842947525122,
      "grad_norm": 1.3325408697128296,
      "learning_rate": 5.365126676602087e-06,
      "loss": 0.0686,
      "step": 1270
    },
    {
      "epoch": 1.9054707852623745,
      "grad_norm": 1.0242035388946533,
      "learning_rate": 4.619970193740686e-06,
      "loss": 0.0628,
      "step": 1280
    },
    {
      "epoch": 1.9203572757722367,
      "grad_norm": 1.3615723848342896,
      "learning_rate": 3.874813710879284e-06,
      "loss": 0.0835,
      "step": 1290
    },
    {
      "epoch": 1.935243766282099,
      "grad_norm": 2.0448062419891357,
      "learning_rate": 3.129657228017884e-06,
      "loss": 0.0807,
      "step": 1300
    },
    {
      "epoch": 1.9501302567919612,
      "grad_norm": 1.417109489440918,
      "learning_rate": 2.384500745156483e-06,
      "loss": 0.0804,
      "step": 1310
    },
    {
      "epoch": 1.9650167473018236,
      "grad_norm": 0.8562682271003723,
      "learning_rate": 1.639344262295082e-06,
      "loss": 0.0728,
      "step": 1320
    },
    {
      "epoch": 1.9799032378116859,
      "grad_norm": 1.6923797130584717,
      "learning_rate": 8.941877794336812e-07,
      "loss": 0.0733,
      "step": 1330
    },
    {
      "epoch": 1.9947897283215483,
      "grad_norm": 1.532125473022461,
      "learning_rate": 1.4903129657228018e-07,
      "loss": 0.0749,
      "step": 1340
    }
  ],
  "logging_steps": 10,
  "max_steps": 1342,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.283705743264461e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
